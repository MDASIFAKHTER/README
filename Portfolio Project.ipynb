{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salary Predictions Based on Job Descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - DEFINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 1 Define the problem ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Salary based on the job descriptions.\n",
    "Job descriptions could have various attributes for the same :\n",
    "1.) Job Type : Role /  Position for the Job ( Ex : Executive / Management / Fresher / Mid Level Roles etc.) \n",
    "2.) Degree of Education required for the job ( Ex :  Masters / PHD / Bachelors etc. )\n",
    "3.) Field of Study / Major ( Ex : Math /  Computer Science / Biology etc. )\n",
    "4.) Industry ( Ex : Textile /  Automobile / Technology / Health etc. )\n",
    "5.) Years of Experience\n",
    "6.) Miles from Metropolis / How far from the main city  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#info\n",
    "__author__ = \"MD ASIF AKHTER\"\n",
    "__email__ = \"akhter.asif@gmail.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - DISCOVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A\n"
     ]
    }
   ],
   "source": [
    "# Find the Current Directory\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 2 Load the data ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              jobId companyId         jobType       degree      major  \\\n",
      "0  JOB1362684407687    COMP37             CFO      MASTERS       MATH   \n",
      "1  JOB1362684407688    COMP19             CEO  HIGH_SCHOOL       NONE   \n",
      "2  JOB1362684407689    COMP52  VICE_PRESIDENT     DOCTORAL    PHYSICS   \n",
      "3  JOB1362684407690    COMP38         MANAGER     DOCTORAL  CHEMISTRY   \n",
      "4  JOB1362684407691     COMP7  VICE_PRESIDENT    BACHELORS    PHYSICS   \n",
      "\n",
      "  industry  yearsExperience  milesFromMetropolis  \n",
      "0   HEALTH               10                   83  \n",
      "1      WEB                3                   73  \n",
      "2   HEALTH               10                   38  \n",
      "3     AUTO                8                   17  \n",
      "4  FINANCE                8                   16  \n"
     ]
    }
   ],
   "source": [
    "#load the data into a Pandas dataframe\n",
    "train_features = pd.read_csv(\"train_features.csv\")\n",
    "print(train_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              jobId  salary\n",
      "0  JOB1362684407687     130\n",
      "1  JOB1362684407688     101\n",
      "2  JOB1362684407689     137\n",
      "3  JOB1362684407690     142\n",
      "4  JOB1362684407691     163\n"
     ]
    }
   ],
   "source": [
    "train_salaries = pd.read_csv(\"train_salaries.csv\")\n",
    "print(train_salaries.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              jobId companyId  jobType       degree    major industry  \\\n",
      "0  JOB1362685407687    COMP33  MANAGER  HIGH_SCHOOL     NONE   HEALTH   \n",
      "1  JOB1362685407688    COMP13   JUNIOR         NONE     NONE     AUTO   \n",
      "2  JOB1362685407689    COMP10      CTO      MASTERS  BIOLOGY   HEALTH   \n",
      "3  JOB1362685407690    COMP21  MANAGER  HIGH_SCHOOL     NONE      OIL   \n",
      "4  JOB1362685407691    COMP36   JUNIOR     DOCTORAL  BIOLOGY      OIL   \n",
      "\n",
      "   yearsExperience  milesFromMetropolis  \n",
      "0               22                   73  \n",
      "1               20                   47  \n",
      "2               17                    9  \n",
      "3               14                   96  \n",
      "4               10                   44  \n"
     ]
    }
   ],
   "source": [
    "test_features = pd.read_csv(\"test_features.csv\")\n",
    "print(test_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Features Data has 1000000 rows and 8 columns\n",
      "Train Salaries Data has 1000000 rows and 2 columns\n",
      "\n",
      "\n",
      "              jobId companyId         jobType       degree      major  \\\n",
      "0  JOB1362684407687    COMP37             CFO      MASTERS       MATH   \n",
      "1  JOB1362684407688    COMP19             CEO  HIGH_SCHOOL       NONE   \n",
      "2  JOB1362684407689    COMP52  VICE_PRESIDENT     DOCTORAL    PHYSICS   \n",
      "3  JOB1362684407690    COMP38         MANAGER     DOCTORAL  CHEMISTRY   \n",
      "4  JOB1362684407691     COMP7  VICE_PRESIDENT    BACHELORS    PHYSICS   \n",
      "\n",
      "  industry  yearsExperience  milesFromMetropolis  salary  \n",
      "0   HEALTH               10                   83     130  \n",
      "1      WEB                3                   73     101  \n",
      "2   HEALTH               10                   38     137  \n",
      "3     AUTO                8                   17     142  \n",
      "4  FINANCE                8                   16     163  \n",
      "\n",
      "\n",
      "(1000000, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Features Data has \" + str(train_features.shape[0]) + \" rows and \" + str(train_features.shape[1]) + \" columns\" )\n",
    "print(\"Train Salaries Data has \" + str(train_salaries.shape[0]) + \" rows and \" + str(train_salaries.shape[1]) + \" columns\" )\n",
    "\n",
    "#Looks like both the train data has equal number of records , we can join them.\n",
    "\n",
    "train_data = pd.merge(train_features , train_salaries , on = 'jobId')\n",
    "\n",
    "print(\"\\n\")\n",
    "print(train_data.head())\n",
    "print(\"\\n\")\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 3 Clean the data ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(999995, 9)\n",
      "0\n",
      "Missing Values : \n",
      "\n",
      "\n",
      "jobId                  0\n",
      "companyId              0\n",
      "jobType                0\n",
      "degree                 0\n",
      "major                  0\n",
      "industry               0\n",
      "yearsExperience        0\n",
      "milesFromMetropolis    0\n",
      "salary                 0\n",
      "is_duplicated          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#look for duplicate data, invalid data (e.g. salaries <=0), or corrupt data and remove it\n",
    "\n",
    "# Check for any salary less than 0 \n",
    "train_data_salary_less_than_0 = train_data[train_data['salary'] <= 0]\n",
    "\n",
    "print(len(train_data_salary_less_than_0))\n",
    "\n",
    "# There are 5 records where salary is 0 , this could be corrupt data , we can drop them as they are very less compared \n",
    "# to the entire training set of 1 million records.\n",
    "\n",
    "train_data = train_data.drop(train_data_salary_less_than_0.index.tolist())\n",
    "print(train_data.shape)\n",
    "      \n",
    "# Check for duplicates \n",
    "train_data['is_duplicated'] = train_data.duplicated()\n",
    "print(train_data['is_duplicated'].sum())\n",
    "\n",
    "# The training data has no duplicates , hnece we need not drop any\n",
    "# If duplicates , we could use df.drop_duplicates() to remove duplicates.\n",
    "\n",
    "# Check for any other corrupt data / missing data\n",
    "print(\"Missing Values : \")\n",
    "print(\"\\n\")\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating another copy, so that we can use one hot encoding in the future.\n",
    "# Currently for EDA and  Visualization using category code values \n",
    "# Use One hot encoding for the model building as it will generate more features which could be helpful.\n",
    "train_df = train_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 4 Explore the data (EDA) ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Summary :  \n",
      "\n",
      "                   jobId companyId jobType       degree   major industry  \\\n",
      "count             999995    999995  999995       999995  999995   999995   \n",
      "unique            999995        63       8            5       9        7   \n",
      "top     JOB1362685181948    COMP39  SENIOR  HIGH_SCHOOL    NONE      WEB   \n",
      "freq                   1     16193  125886       236975  532353   143205   \n",
      "mean                 NaN       NaN     NaN          NaN     NaN      NaN   \n",
      "std                  NaN       NaN     NaN          NaN     NaN      NaN   \n",
      "min                  NaN       NaN     NaN          NaN     NaN      NaN   \n",
      "25%                  NaN       NaN     NaN          NaN     NaN      NaN   \n",
      "50%                  NaN       NaN     NaN          NaN     NaN      NaN   \n",
      "75%                  NaN       NaN     NaN          NaN     NaN      NaN   \n",
      "max                  NaN       NaN     NaN          NaN     NaN      NaN   \n",
      "\n",
      "        yearsExperience  milesFromMetropolis         salary is_duplicated  \n",
      "count     999995.000000        999995.000000  999995.000000        999995  \n",
      "unique              NaN                  NaN            NaN             1  \n",
      "top                 NaN                  NaN            NaN         False  \n",
      "freq                NaN                  NaN            NaN        999995  \n",
      "mean          11.992407            49.529381     116.062398           NaN  \n",
      "std            7.212390            28.877721      38.717163           NaN  \n",
      "min            0.000000             0.000000      17.000000           NaN  \n",
      "25%            6.000000            25.000000      88.000000           NaN  \n",
      "50%           12.000000            50.000000     114.000000           NaN  \n",
      "75%           18.000000            75.000000     141.000000           NaN  \n",
      "max           24.000000            99.000000     301.000000           NaN  \n",
      "\n",
      "\n",
      "jobId                  object\n",
      "companyId              object\n",
      "jobType                object\n",
      "degree                 object\n",
      "major                  object\n",
      "industry               object\n",
      "yearsExperience         int64\n",
      "milesFromMetropolis     int64\n",
      "salary                  int64\n",
      "is_duplicated            bool\n",
      "dtype: object\n",
      "\n",
      " Correlation : All Features vs Target \n",
      "\n",
      "jobType               -0.228672\n",
      "degree                -0.231794\n",
      "major                 -0.262435\n",
      "industry               0.086500\n",
      "yearsExperience        0.375013\n",
      "milesFromMetropolis   -0.297686\n",
      "salary                 1.000000\n",
      "is_duplicated               NaN\n",
      "Name: salary, dtype: float64\n",
      "\n",
      " Correlation : All Features vs Features \n",
      "\n",
      "                      jobType    degree     major  industry  yearsExperience  \\\n",
      "jobType              1.000000 -0.020084 -0.020773  0.000066        -0.000185   \n",
      "degree              -0.020084  1.000000  0.370090  0.001548        -0.000140   \n",
      "major               -0.020773  0.370090  1.000000  0.001077         0.000013   \n",
      "industry             0.000066  0.001548  0.001077  1.000000         0.000264   \n",
      "yearsExperience     -0.000185 -0.000140  0.000013  0.000264         1.000000   \n",
      "milesFromMetropolis -0.000362 -0.001360 -0.001369 -0.000820         0.000672   \n",
      "salary              -0.228672 -0.231794 -0.262435  0.086500         0.375013   \n",
      "is_duplicated             NaN       NaN       NaN       NaN              NaN   \n",
      "\n",
      "                     milesFromMetropolis    salary  is_duplicated  \n",
      "jobType                        -0.000362 -0.228672            NaN  \n",
      "degree                         -0.001360 -0.231794            NaN  \n",
      "major                          -0.001369 -0.262435            NaN  \n",
      "industry                       -0.000820  0.086500            NaN  \n",
      "yearsExperience                 0.000672  0.375013            NaN  \n",
      "milesFromMetropolis             1.000000 -0.297686            NaN  \n",
      "salary                         -0.297686  1.000000            NaN  \n",
      "is_duplicated                        NaN       NaN            NaN  \n"
     ]
    }
   ],
   "source": [
    "#summarize each feature variable\n",
    "#summarize the target variable\n",
    "\n",
    "# we can quickly check the summary for all the columns using the describe method\n",
    "\n",
    "print('\\n Summary :  \\n')\n",
    "print(train_data.describe(include='all'))\n",
    "\n",
    "# Identify the Types of Each column\n",
    "print(\"\\n\")\n",
    "print(train_data.dtypes)\n",
    "\n",
    "#look for correlation between each feature and the target\n",
    "\n",
    "# for correlation we need to convert the category columns to  numeric\n",
    "# In this data we have all these columns as object types - Job Id , Company Id , Job Type , Degree , Major , Industry\n",
    "# Job ID and Company ID do not serve much purpose as they could be unique values for each job or each company\n",
    "\n",
    "#convert categorical varibale to numeric values.\n",
    "train_data['jobType'] = train_data['jobType'].astype('category').cat.codes #Job Type has 8 unique Values \n",
    "train_data['degree'] = train_data['degree'].astype('category').cat.codes # Degree has 5 Unique Values\n",
    "train_data['major'] = train_data['major'].astype('category').cat.codes # Major has 9 Unique Values\n",
    "train_data['industry'] = train_data['industry'].astype('category').cat.codes # Industry has 7 Unique Values\n",
    "\n",
    "#Correlation between each feature and target \n",
    "print(\"\\n Correlation : All Features vs Target \\n\")\n",
    "print(train_data[train_data.columns[2:]].corr()['salary'][:])\n",
    "\n",
    "#look for correlation between features \n",
    "print(\"\\n Correlation : All Features vs Features \\n\")\n",
    "print(train_data.corr()) # This will create the correlation matrix with all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   jobType  degree  major  industry  yearsExperience  milesFromMetropolis  \\\n",
      "0        1       3      6         3               10                   83   \n",
      "1        0       2      7         6                3                   73   \n",
      "2        7       1      8         3               10                   38   \n",
      "3        5       1      2         0                8                   17   \n",
      "4        7       0      8         2                8                   16   \n",
      "\n",
      "   salary  \n",
      "0     130  \n",
      "1     101  \n",
      "2     137  \n",
      "3     142  \n",
      "4     163  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Drop Columns \n",
    "# We do not need job id , company id , isduplicated flag as they dont serve any purpose further.\n",
    "\n",
    "train_data = train_data.drop(columns = ['jobId' , 'companyId' , 'is_duplicated'])\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the correlation matrix \n",
    "\n",
    "# Use Seaborn Heatmap \n",
    "import seaborn as sns\n",
    "\n",
    "corr = train_data.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "with sns.axes_style(\"white\"):\n",
    "    ax = sns.heatmap(corr, mask=mask, vmax=1, vmin=-1, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   yearsExperience  milesFromMetropolis  CEO  CFO  CTO  JANITOR  JUNIOR  \\\n",
      "0               10                   83    0    1    0        0       0   \n",
      "1                3                   73    1    0    0        0       0   \n",
      "2               10                   38    0    0    0        0       0   \n",
      "3                8                   17    0    0    0        0       0   \n",
      "4                8                   16    0    0    0        0       0   \n",
      "\n",
      "   MANAGER  SENIOR  VICE_PRESIDENT   ...    NONE  PHYSICS  AUTO  EDUCATION  \\\n",
      "0        0       0               0   ...       0        0     0          0   \n",
      "1        0       0               0   ...       1        0     0          0   \n",
      "2        0       0               1   ...       0        1     0          0   \n",
      "3        1       0               0   ...       0        0     1          0   \n",
      "4        0       0               1   ...       0        1     0          0   \n",
      "\n",
      "   FINANCE  HEALTH  OIL  SERVICE  WEB  salary  \n",
      "0        0       1    0        0    0     130  \n",
      "1        0       0    0        0    1     101  \n",
      "2        0       1    0        0    0     137  \n",
      "3        0       0    0        0    0     142  \n",
      "4        1       0    0        0    0     163  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# One Hot Encoding \n",
    "\n",
    "# There are few categorical values in the data and we do not have any orderly relationship within the category codes.\n",
    "# Use One hot encoding so that machine learning model performs better\n",
    "\n",
    "train_jobtype = pd.get_dummies(train_df['jobType'])\n",
    "train_degree = pd.get_dummies(train_df['degree'])\n",
    "train_major = pd.get_dummies(train_df['major'])\n",
    "train_industry = pd.get_dummies(train_df['industry'])\n",
    "\n",
    "\n",
    "train_df = train_df.drop(columns = ['jobType' , 'degree' , 'major' ,'industry' ])\n",
    "\n",
    "train_df_final = pd.concat([train_df[['yearsExperience','milesFromMetropolis']] , train_jobtype , train_degree , train_major , train_industry , train_df[['salary']]] , axis=1)\n",
    "print(train_df_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     yearsExperience  milesFromMetropolis       CEO       CFO  \\\n",
      "yearsExperience             1.000000             0.000672  0.000307 -0.000103   \n",
      "milesFromMetropolis         0.000672             1.000000 -0.000666  0.000566   \n",
      "CEO                         0.000307            -0.000666  1.000000 -0.142301   \n",
      "CFO                        -0.000103             0.000566 -0.142301  1.000000   \n",
      "CTO                         0.000967             0.000674 -0.142742 -0.142475   \n",
      "JANITOR                    -0.001192            -0.001120 -0.142694 -0.142427   \n",
      "JUNIOR                     -0.000001             0.001713 -0.142447 -0.142180   \n",
      "MANAGER                    -0.000269            -0.000406 -0.142791 -0.142524   \n",
      "SENIOR                      0.000222             0.000567 -0.143290 -0.143022   \n",
      "VICE_PRESIDENT              0.000068            -0.001325 -0.142866 -0.142598   \n",
      "BACHELORS                  -0.000407             0.000963  0.025655  0.025148   \n",
      "DOCTORAL                    0.000695             0.001272  0.025970  0.023008   \n",
      "HIGH_SCHOOL                 0.000240            -0.001352 -0.034503 -0.032499   \n",
      "MASTERS                    -0.000474             0.000394  0.024003  0.025979   \n",
      "NONE                       -0.000074            -0.000999 -0.033141 -0.033808   \n",
      "BIOLOGY                    -0.000041            -0.000042  0.013468  0.014313   \n",
      "BUSINESS                    0.000651             0.000871  0.012753  0.013454   \n",
      "CHEMISTRY                  -0.000597             0.000205  0.014098  0.013372   \n",
      "COMPSCI                    -0.000460             0.001265  0.015541  0.014204   \n",
      "ENGINEERING                -0.000156             0.000417  0.012558  0.013350   \n",
      "LITERATURE                  0.000643             0.001426  0.013435  0.010553   \n",
      "MATH                       -0.000005            -0.000912  0.011797  0.014043   \n",
      "NONE                        0.000110            -0.001626 -0.050958 -0.050205   \n",
      "PHYSICS                    -0.000269             0.000221  0.014718  0.013497   \n",
      "AUTO                       -0.001002             0.000345  0.000623 -0.001416   \n",
      "EDUCATION                   0.000436             0.000807  0.000149 -0.000930   \n",
      "FINANCE                     0.000977             0.000050  0.000747  0.000778   \n",
      "HEALTH                     -0.001106            -0.000400 -0.001616  0.001920   \n",
      "OIL                         0.000801            -0.000550  0.000591 -0.000634   \n",
      "SERVICE                     0.000128             0.000685 -0.000825 -0.000771   \n",
      "WEB                        -0.000233            -0.000935  0.000329  0.001052   \n",
      "salary                      0.375013            -0.297686  0.285246  0.188803   \n",
      "\n",
      "                          CTO   JANITOR    JUNIOR   MANAGER    SENIOR  \\\n",
      "yearsExperience      0.000967 -0.001192 -0.000001 -0.000269  0.000222   \n",
      "milesFromMetropolis  0.000674 -0.001120  0.001713 -0.000406  0.000567   \n",
      "CEO                 -0.142742 -0.142694 -0.142447 -0.142791 -0.143290   \n",
      "CFO                 -0.142475 -0.142427 -0.142180 -0.142524 -0.143022   \n",
      "CTO                  1.000000 -0.142868 -0.142621 -0.142966 -0.143465   \n",
      "JANITOR             -0.142868  1.000000 -0.142572 -0.142917 -0.143417   \n",
      "JUNIOR              -0.142621 -0.142572  1.000000 -0.142670 -0.143168   \n",
      "MANAGER             -0.142966 -0.142917 -0.142670  1.000000 -0.143515   \n",
      "SENIOR              -0.143465 -0.143417 -0.143168 -0.143515  1.000000   \n",
      "VICE_PRESIDENT      -0.143040 -0.142992 -0.142744 -0.143089 -0.143589   \n",
      "BACHELORS            0.024734 -0.174354  0.023933  0.024314  0.025562   \n",
      "DOCTORAL             0.023785 -0.174274  0.025251  0.024048  0.026186   \n",
      "HIGH_SCHOOL         -0.033698  0.233343 -0.031654 -0.033801 -0.035347   \n",
      "MASTERS              0.026805 -0.174242  0.023864  0.025541  0.025028   \n",
      "NONE                -0.033674  0.234325 -0.033681 -0.032298 -0.033323   \n",
      "BIOLOGY              0.011759 -0.094099  0.012119  0.014252  0.014849   \n",
      "BUSINESS             0.013957 -0.094218  0.013443  0.012918  0.013387   \n",
      "CHEMISTRY            0.013793 -0.094523  0.013051  0.011550  0.015053   \n",
      "COMPSCI              0.014668 -0.094102  0.013083  0.012133  0.013249   \n",
      "ENGINEERING          0.011818 -0.094283  0.015015  0.013689  0.014630   \n",
      "LITERATURE           0.014675 -0.094360  0.013610  0.014884  0.014397   \n",
      "MATH                 0.014514 -0.093603  0.013190  0.013315  0.011688   \n",
      "NONE                -0.050948  0.354202 -0.049764 -0.050402 -0.052190   \n",
      "PHYSICS              0.013176 -0.094126  0.012325  0.014457  0.013728   \n",
      "AUTO                -0.000735  0.001887  0.000023  0.001892 -0.001519   \n",
      "EDUCATION            0.000450  0.000196  0.001565 -0.000860  0.000827   \n",
      "FINANCE             -0.000793 -0.000477 -0.000355  0.000713 -0.000714   \n",
      "HEALTH              -0.001581 -0.001101  0.001452 -0.001111 -0.000224   \n",
      "OIL                  0.001938 -0.001272 -0.002537  0.000151  0.001871   \n",
      "SERVICE              0.000922  0.000235 -0.000111  0.000120  0.000497   \n",
      "WEB                 -0.000200  0.000530 -0.000037 -0.000905 -0.000737   \n",
      "salary               0.189608 -0.441676 -0.201987 -0.006778 -0.103650   \n",
      "\n",
      "                     VICE_PRESIDENT    ...         NONE   PHYSICS      AUTO  \\\n",
      "yearsExperience            0.000068    ...     0.000110 -0.000269 -0.001002   \n",
      "milesFromMetropolis       -0.001325    ...    -0.001626  0.000221  0.000345   \n",
      "CEO                       -0.142866    ...    -0.050958  0.014718  0.000623   \n",
      "CFO                       -0.142598    ...    -0.050205  0.013497 -0.001416   \n",
      "CTO                       -0.143040    ...    -0.050948  0.013176 -0.000735   \n",
      "JANITOR                   -0.142992    ...     0.354202 -0.094126  0.001887   \n",
      "JUNIOR                    -0.142744    ...    -0.049764  0.012325  0.000023   \n",
      "MANAGER                   -0.143089    ...    -0.050402  0.014457  0.001892   \n",
      "SENIOR                    -0.143589    ...    -0.052190  0.013728 -0.001519   \n",
      "VICE_PRESIDENT             1.000000    ...    -0.049690  0.012214 -0.000752   \n",
      "BACHELORS                  0.024987    ...    -0.389512  0.101519  0.000950   \n",
      "DOCTORAL                   0.026001    ...    -0.388091  0.102870  0.001228   \n",
      "HIGH_SCHOOL               -0.031806    ...     0.522324 -0.138802 -0.001973   \n",
      "MASTERS                    0.023004    ...    -0.390156  0.105933 -0.000399   \n",
      "NONE                      -0.034375    ...     0.522148 -0.138756  0.000382   \n",
      "BIOLOGY                    0.013323    ...    -0.265665 -0.062016 -0.000875   \n",
      "BUSINESS                   0.014294    ...    -0.266001 -0.062095  0.000126   \n",
      "CHEMISTRY                  0.013590    ...    -0.266862 -0.062296  0.000441   \n",
      "COMPSCI                    0.011218    ...    -0.265672 -0.062018 -0.000307   \n",
      "ENGINEERING                0.013211    ...    -0.266184 -0.062137  0.000833   \n",
      "LITERATURE                 0.012787    ...    -0.266401 -0.062188  0.001539   \n",
      "MATH                       0.015050    ...    -0.264263 -0.061689  0.000832   \n",
      "NONE                      -0.049690    ...     1.000000 -0.265740 -0.001600   \n",
      "PHYSICS                    0.012214    ...    -0.265740  1.000000  0.000813   \n",
      "AUTO                      -0.000752    ...    -0.001600  0.000813  1.000000   \n",
      "EDUCATION                 -0.001398    ...     0.001148 -0.001001 -0.166699   \n",
      "FINANCE                    0.000106    ...    -0.000696 -0.001168 -0.166731   \n",
      "HEALTH                     0.002264    ...    -0.000925  0.000910 -0.166655   \n",
      "OIL                       -0.000119    ...     0.000719 -0.000234 -0.166665   \n",
      "SERVICE                   -0.000072    ...     0.001177  0.000066 -0.166576   \n",
      "WEB                       -0.000028    ...     0.000177  0.000613 -0.166961   \n",
      "salary                     0.090947    ...    -0.371435  0.092056 -0.069904   \n",
      "\n",
      "                     EDUCATION   FINANCE    HEALTH       OIL   SERVICE  \\\n",
      "yearsExperience       0.000436  0.000977 -0.001106  0.000801  0.000128   \n",
      "milesFromMetropolis   0.000807  0.000050 -0.000400 -0.000550  0.000685   \n",
      "CEO                   0.000149  0.000747 -0.001616  0.000591 -0.000825   \n",
      "CFO                  -0.000930  0.000778  0.001920 -0.000634 -0.000771   \n",
      "CTO                   0.000450 -0.000793 -0.001581  0.001938  0.000922   \n",
      "JANITOR               0.000196 -0.000477 -0.001101 -0.001272  0.000235   \n",
      "JUNIOR                0.001565 -0.000355  0.001452 -0.002537 -0.000111   \n",
      "MANAGER              -0.000860  0.000713 -0.001111  0.000151  0.000120   \n",
      "SENIOR                0.000827 -0.000714 -0.000224  0.001871  0.000497   \n",
      "VICE_PRESIDENT       -0.001398  0.000106  0.002264 -0.000119 -0.000072   \n",
      "BACHELORS             0.000592 -0.000056 -0.000383 -0.001004  0.000236   \n",
      "DOCTORAL              0.000112  0.000230  0.000534  0.001131 -0.002366   \n",
      "HIGH_SCHOOL           0.001434 -0.000584  0.000252  0.000846 -0.001130   \n",
      "MASTERS              -0.001682  0.000316  0.000725 -0.000407  0.000555   \n",
      "NONE                 -0.000560  0.000145 -0.001036 -0.000596  0.002538   \n",
      "BIOLOGY               0.000528 -0.000992  0.001842 -0.000473  0.001059   \n",
      "BUSINESS              0.001710  0.000289 -0.000119 -0.000605  0.000500   \n",
      "CHEMISTRY            -0.000662  0.000324  0.000513 -0.000846 -0.000181   \n",
      "COMPSCI               0.000352 -0.000059 -0.000407  0.000070 -0.000288   \n",
      "ENGINEERING          -0.000467  0.001373 -0.001687 -0.001102  0.000489   \n",
      "LITERATURE           -0.001985  0.001046  0.000116  0.000823 -0.002222   \n",
      "MATH                 -0.000918  0.000665  0.000805  0.000843 -0.001931   \n",
      "NONE                  0.001148 -0.000696 -0.000925  0.000719  0.001177   \n",
      "PHYSICS              -0.001001 -0.001168  0.000910 -0.000234  0.000066   \n",
      "AUTO                 -0.166699 -0.166731 -0.166655 -0.166665 -0.166576   \n",
      "EDUCATION             1.000000 -0.166648 -0.166572 -0.166582 -0.166493   \n",
      "FINANCE              -0.166648  1.000000 -0.166604 -0.166614 -0.166525   \n",
      "HEALTH               -0.166572 -0.166604  1.000000 -0.166539 -0.166450   \n",
      "OIL                  -0.166582 -0.166614 -0.166539  1.000000 -0.166460   \n",
      "SERVICE              -0.166493 -0.166525 -0.166450 -0.166460  1.000000   \n",
      "WEB                  -0.166878 -0.166910 -0.166835 -0.166845 -0.166756   \n",
      "salary               -0.175158  0.154853 -0.003445  0.156966 -0.122370   \n",
      "\n",
      "                          WEB    salary  \n",
      "yearsExperience     -0.000233  0.375013  \n",
      "milesFromMetropolis -0.000935 -0.297686  \n",
      "CEO                  0.000329  0.285246  \n",
      "CFO                  0.001052  0.188803  \n",
      "CTO                 -0.000200  0.189608  \n",
      "JANITOR              0.000530 -0.441676  \n",
      "JUNIOR              -0.000037 -0.201987  \n",
      "MANAGER             -0.000905 -0.006778  \n",
      "SENIOR              -0.000737 -0.103650  \n",
      "VICE_PRESIDENT      -0.000028  0.090947  \n",
      "BACHELORS           -0.000337  0.111919  \n",
      "DOCTORAL            -0.000870  0.231406  \n",
      "HIGH_SCHOOL          0.001154 -0.203549  \n",
      "MASTERS              0.000891  0.171997  \n",
      "NONE                -0.000871 -0.257356  \n",
      "BIOLOGY             -0.001086  0.076339  \n",
      "BUSINESS            -0.001899  0.126123  \n",
      "CHEMISTRY            0.000409  0.084044  \n",
      "COMPSCI              0.000638  0.102986  \n",
      "ENGINEERING          0.000559  0.144203  \n",
      "LITERATURE           0.000682  0.053918  \n",
      "MATH                -0.000297  0.110413  \n",
      "NONE                 0.000177 -0.371435  \n",
      "PHYSICS              0.000613  0.092056  \n",
      "AUTO                -0.166961 -0.069904  \n",
      "EDUCATION           -0.166878 -0.175158  \n",
      "FINANCE             -0.166910  0.154853  \n",
      "HEALTH              -0.166835 -0.003445  \n",
      "OIL                 -0.166845  0.156966  \n",
      "SERVICE             -0.166756 -0.122370  \n",
      "WEB                  1.000000  0.058953  \n",
      "salary               0.058953  1.000000  \n",
      "\n",
      "[32 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# Correlation Matrix for the entire training data after one hot encoding\n",
    "\n",
    "train_df_final_corr = train_df_final.corr()\n",
    "print(train_df_final_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 5 Establish a baseline ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   industry  salary  salary_avg\n",
      "0         3     130  115.735540\n",
      "1         6     101  121.645362\n",
      "2         3     137  115.735540\n",
      "3         0     142  109.435222\n",
      "4         2     163  130.747659\n"
     ]
    }
   ],
   "source": [
    "#select a reasonable metric (MSE in this case)\n",
    "#create an extremely simple model and measure its efficacy\n",
    "#e.g. use \"average salary\" for each industry as your model and then measure MSE\n",
    "#during 5-fold cross-validation\n",
    "\n",
    "# Create a baseline  model with just industry , salary and salary_avg ( average salary for each industry ) and find MSE.\n",
    "# use 5 fold cross validation\n",
    "\n",
    "train_data_baseline = train_data[['industry','salary']]\n",
    "train_data_baseline = train_data_baseline.set_index(['industry'])\n",
    "\n",
    "mean_val = train_data_baseline.groupby('industry')['salary'].mean()\n",
    "\n",
    "train_data_baseline['salary_avg'] = mean_val\n",
    "train_data_baseline = train_data_baseline.reset_index()\n",
    "\n",
    "print(train_data_baseline.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n",
      "\n",
      " Fold :  1 \n",
      "\n",
      "TRAIN: [199999 200000 200001 ... 999992 999993 999994] TEST: [     0      1      2 ... 199996 199997 199998]\n",
      "MSE 1369.1806222423513\n",
      "\n",
      " Fold :  2 \n",
      "\n",
      "TRAIN: [     0      1      2 ... 999992 999993 999994] TEST: [199999 200000 200001 ... 399995 399996 399997]\n",
      "MSE 1368.6023543911754\n",
      "\n",
      " Fold :  3 \n",
      "\n",
      "TRAIN: [     0      1      2 ... 999992 999993 999994] TEST: [399998 399999 400000 ... 599994 599995 599996]\n",
      "MSE 1371.3591525123234\n",
      "\n",
      " Fold :  4 \n",
      "\n",
      "TRAIN: [     0      1      2 ... 999992 999993 999994] TEST: [599997 599998 599999 ... 799993 799994 799995]\n",
      "MSE 1362.2162691114431\n",
      "\n",
      " Fold :  5 \n",
      "\n",
      "TRAIN: [     0      1      2 ... 799993 799994 799995] TEST: [799996 799997 799998 ... 999992 999993 999994]\n",
      "MSE 1364.2563556689843\n",
      "Average MSE 1367.1229507852554\n"
     ]
    }
   ],
   "source": [
    "# Cross validation with 5 folds initial baseline model \n",
    "\n",
    "# Baseline model just has 1 feature ( salary ) and mean squared error is calculated with salary and average salary by industry\n",
    "# This gives a very high MSE ( 1367 ) - average mse from 5 folds.\n",
    " \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = train_data_baseline['industry']\n",
    "y = train_data_baseline['salary']\n",
    "y_baseline = train_data_baseline['salary_avg']\n",
    "\n",
    "kf = KFold(n_splits=5) # Define the split - into 5 folds \n",
    "kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator\n",
    "print(kf) \n",
    "\n",
    "mean_squared_err = []\n",
    "k = 0 \n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    k += 1\n",
    "    print('\\n Fold : ', k ,'\\n')\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    \n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_base_train , y_base_test = y_baseline[train_index], y_baseline[test_index]\n",
    "    \n",
    "    error = mean_squared_error(y_test, y_base_test)\n",
    "    print('MSE', error)\n",
    "    mean_squared_err.append(error)\n",
    "    \n",
    "print('Average MSE', np.array(mean_squared_err).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 6 Hypothesize solution ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#brainstorm 3 models that you think may improve results over the baseline model based\n",
    "#on your "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brainstorm 3 models that you think may improve results over the baseline model based on your EDA and explain why they're reasonable solutions here.\n",
    "\n",
    "Also write down any new features that you think you should try adding to the model based on your EDA, e.g. interaction variables, summary statistics for each group, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add more features , use the one hot encoding features dataframe and do a linear regression with more features.\n",
    "2.) Use Polynomial Features.\n",
    "3.) Use Random Forest Model\n",
    "\n",
    "Brainstorm 3 models that you think may improve results over the baseline model based on your EDA and explain why they're reasonable solutions here.\n",
    "Also write down any new features that you think you should try adding to the model based on your EDA, e.g. interaction variables, summary statistics for each group, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - DEVELOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will cycle through creating features, tuning models, and training/validing models (steps 7-9) until you've reached your efficacy goal\n",
    "\n",
    "#### Your metric will be MSE and your goal is:\n",
    " - <360 for entry-level data science roles\n",
    " - <320 for senior data science roles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 7 Engineer features  ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   yearsExperience  milesFromMetropolis  CEO  CFO  CTO  JANITOR  JUNIOR  \\\n",
      "0               10                   83    0    1    0        0       0   \n",
      "1                3                   73    1    0    0        0       0   \n",
      "2               10                   38    0    0    0        0       0   \n",
      "3                8                   17    0    0    0        0       0   \n",
      "4                8                   16    0    0    0        0       0   \n",
      "\n",
      "   MANAGER  SENIOR  VICE_PRESIDENT   ...    NONE  PHYSICS  AUTO  EDUCATION  \\\n",
      "0        0       0               0   ...       0        0     0          0   \n",
      "1        0       0               0   ...       1        0     0          0   \n",
      "2        0       0               1   ...       0        1     0          0   \n",
      "3        1       0               0   ...       0        0     1          0   \n",
      "4        0       0               1   ...       0        1     0          0   \n",
      "\n",
      "   FINANCE  HEALTH  OIL  SERVICE  WEB  salary  \n",
      "0        0       1    0        0    0     130  \n",
      "1        0       0    0        0    1     101  \n",
      "2        0       1    0        0    0     137  \n",
      "3        0       0    0        0    0     142  \n",
      "4        1       0    0        0    0     163  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "#make sure that data is ready for modeling\n",
    "#create any new features needed to potentially enhance model\n",
    "\n",
    "# Try model 1 ( linear regression with more features)\n",
    "\n",
    "\n",
    "#y = train_df_final['salary']\n",
    "X = train_df_final.drop(['salary'] , 1)\n",
    "y = train_df_final[['salary']]\n",
    "\n",
    "print(train_df_final.head())\n",
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 8 Create models ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999995, 31)\n",
      "(999995, 1)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "#create and tune the models that you brainstormed during part 2\n",
    "\n",
    "# make sure the data is scaled and all the data falls in the same scale ,\n",
    "# so that the model doesnt treat some values differently , using minmax as the \n",
    "# value ranges from o to 1 and are not normally distributed.\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# data scaling\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "cols = X.columns\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=cols)\n",
    "\n",
    "print(X_scaled.shape)\n",
    "print(y.shape)\n",
    "print(type(X_scaled))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 9 Test models ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n",
      "\n",
      "Fold :  1 \n",
      "\n",
      "TRAIN: [199999 200000 200001 ... 999992 999993 999994] TEST: [     0      1      2 ... 199996 199997 199998]\n",
      "MSE 386.3175723903217\n",
      "\n",
      "Fold :  2 \n",
      "\n",
      "TRAIN: [     0      1      2 ... 999992 999993 999994] TEST: [199999 200000 200001 ... 399995 399996 399997]\n",
      "MSE 385.18601327564744\n",
      "\n",
      "Fold :  3 \n",
      "\n",
      "TRAIN: [     0      1      2 ... 999992 999993 999994] TEST: [399998 399999 400000 ... 599994 599995 599996]\n",
      "MSE 385.99829824855607\n",
      "\n",
      "Fold :  4 \n",
      "\n",
      "TRAIN: [     0      1      2 ... 999992 999993 999994] TEST: [599997 599998 599999 ... 799993 799994 799995]\n",
      "MSE 382.5725139532108\n",
      "\n",
      "Fold :  5 \n",
      "\n",
      "TRAIN: [     0      1      2 ... 799993 799994 799995] TEST: [799996 799997 799998 ... 999992 999993 999994]\n",
      "MSE 382.0085928690828\n",
      "Average MSE 384.41659814736374\n"
     ]
    }
   ],
   "source": [
    "# do 5-fold cross validation on models and measure MSE\n",
    "# Linear Regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5) # Define the split - into 5 folds \n",
    "kf.get_n_splits(X_scaled) # returns the number of splitting iterations in the cross-validator\n",
    "print(kf) \n",
    "\n",
    "X_scaled = np.nan_to_num(X_scaled)\n",
    "y = np.nan_to_num(y)\n",
    "\n",
    "mse = []\n",
    "k =0\n",
    "for train_index, test_index in kf.split(X_scaled):\n",
    "    k += 1\n",
    "    print('\\nFold : ', k ,'\\n')\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model_linear_reg = LinearRegression().fit(X_train, y_train)\n",
    "    y_pred = model_linear_reg.predict(X_test)\n",
    "    error = mean_squared_error(y_test, y_pred)\n",
    "    print('MSE', error)\n",
    "    mse.append(error)\n",
    "    \n",
    "print('Average MSE', np.array(mse).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n",
      "\n",
      "Fold 1 \n",
      "\n",
      "TRAIN: [199999 200000 200001 ... 999992 999993 999994] TEST: [     0      1      2 ... 199996 199997 199998]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-91cf79142431>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mX_poly_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mmodel_poly_lin_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mmodel_poly_lin_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_poly_lin_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_poly_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_poly_lin_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_poly_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    487\u001b[0m         X, y, X_offset, y_offset, X_scale = self._preprocess_data(\n\u001b[0;32m    488\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             copy=self.copy_X, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36m_preprocess_data\u001b[1;34m(X, y, fit_intercept, normalize, copy, sample_weight, return_mean)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m     X = check_array(X, copy=copy, accept_sparse=['csr', 'csc'],\n\u001b[1;32m--> 168\u001b[1;33m                     dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[0;32m    169\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;31m# To ensure that array flags are maintained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m         \u001b[1;31m# make sure we actually converted to numeric:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Polynomial Features with Linear Regression\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5) # Define the split - into 5 folds \n",
    "kf.get_n_splits(X_scaled) # returns the number of splitting iterations in the cross-validator\n",
    "print(kf) \n",
    "\n",
    "mse = []\n",
    "k =0\n",
    "for train_index, test_index in kf.split(X_scaled):\n",
    "    k += 1\n",
    "    print('\\nFold', k ,'\\n')\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    poly = PolynomialFeatures(2)\n",
    "    poly = PolynomialFeatures(interaction_only=True)\n",
    "    X_poly_train = poly.fit_transform(X_train)\n",
    "    X_poly_test = poly.fit_transform(X_test)\n",
    "    model_poly_lin_reg = LinearRegression()\n",
    "    model_poly_lin_reg = model_poly_lin_reg.fit(X_poly_train, y_train)\n",
    "    y_pred = model_poly_lin_reg.predict(X_poly_test)\n",
    "    error = mean_squared_error(y_test, y_pred)\n",
    "    print('MSE', error)\n",
    "    mse.append(error)\n",
    "    \n",
    "print('Average MSE', np.array(mse).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n",
      "\n",
      "Fold 1 \n",
      "\n",
      "TRAIN: [199999 200000 200001 ... 999992 999993 999994] TEST: [     0      1      2 ... 199996 199997 199998]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 651.4057270174435\n",
      "\n",
      "Fold 2 \n",
      "\n",
      "TRAIN: [     0      1      2 ... 999992 999993 999994] TEST: [199999 200000 200001 ... 399995 399996 399997]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 649.455990082062\n",
      "\n",
      "Fold 3 \n",
      "\n",
      "TRAIN: [     0      1      2 ... 999992 999993 999994] TEST: [399998 399999 400000 ... 599994 599995 599996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 647.693399919877\n",
      "\n",
      "Fold 4 \n",
      "\n",
      "TRAIN: [     0      1      2 ... 999992 999993 999994] TEST: [599997 599998 599999 ... 799993 799994 799995]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 639.4670800333699\n",
      "\n",
      "Fold 5 \n",
      "\n",
      "TRAIN: [     0      1      2 ... 799993 799994 799995] TEST: [799996 799997 799998 ... 999992 999993 999994]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 639.3490822191781\n",
      "Average MSE 645.4742558543861\n"
     ]
    }
   ],
   "source": [
    "# Random  Forest Regression\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5) # Define the split - into 5 folds \n",
    "kf.get_n_splits(X_scaled) # returns the number of splitting iterations in the cross-validator\n",
    "print(kf) \n",
    "\n",
    "mse = []\n",
    "k =0\n",
    "for train_index, test_index in kf.split(X_scaled):\n",
    "    k += 1\n",
    "    print('\\nFold', k ,'\\n')\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model_rfr = RandomForestRegressor(n_estimators = 250 , max_depth = 6 ).fit(X_train , y_train)\n",
    "    y_pred = model_rfr.predict(X_test)\n",
    "    error = mean_squared_error(y_test, y_pred)\n",
    "    print('MSE', error)\n",
    "    mse.append(error)\n",
    "    \n",
    "print('Average MSE', np.array(mse).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 10 Select best model  ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n"
     ]
    }
   ],
   "source": [
    "#select the model with the lowest error as your \"prodcuction\" model\n",
    "\n",
    "# Looks like the best model among the 3 models is using polynomial features in linear regression with degree 2\n",
    "\n",
    "print(model_poly_lin_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - DEPLOY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 11 Automate pipeline ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write script that trains model on entire training set, saves model to disk,\n",
    "#and scores the \"test\" dataset\n",
    "\n",
    "# Create pipeline so that we can do an end to end process\n",
    "# read the data , clean the data , feature engineering \n",
    "# scaling and normalizing , build model \n",
    "# save the model to disk\n",
    "# load the model to run on the test dataset and predict / calculate the scores accordingly.\n",
    "\n",
    "X_train = pd.DataFrame(X_scaled , columns = X.columns)\n",
    "y_train = pd.DataFrame(y , columns = ['salary'])\n",
    "\n",
    "\n",
    "print(X_train.head())\n",
    "print(X_train.shape)\n",
    "print(type(X_train))\n",
    "\n",
    "\n",
    "print(y_train.head())\n",
    "print(y_train.shape)\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 12 Deploy solution ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'joblib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-4ff20f5b87a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Load Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Feature Eng and Clean the Test Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'joblib' is not defined"
     ]
    }
   ],
   "source": [
    "#save your prediction to a csv file or optionally save them as a table in a SQL database\n",
    "#additionally, you want to save a visualization and summary of your prediction and feature importances\n",
    "#these visualizations and summaries will be extremely useful to business stakeholders\n",
    "\n",
    "# Load Model \n",
    "\n",
    "model_load = joblib.load('model.pkl')\n",
    "\n",
    "# Feature Eng and Clean the Test Data\n",
    "\n",
    "# The test data should have same features as the train data features was modelled upon.\n",
    "\n",
    "test_jobtype = pd.get_dummies(test_features_data['jobType'])\n",
    "test_degree = pd.get_dummies(test_features_data['degree'])\n",
    "test_major = pd.get_dummies(test_features_data['major'])\n",
    "test_industry = pd.get_dummies(test_features_data['industry'])\n",
    "\n",
    "\n",
    "test_df = test_features_data.drop(columns = ['jobId' , 'companyId' , 'jobType' , 'degree' , 'major' , 'industry'])\n",
    "\n",
    "test_df_final = pd.concat([test_df[['yearsExperience','milesFromMetropolis']] , test_jobtype , test_degree , test_major , test_industry] , axis=1)\n",
    "#print(test_df_final.head())\n",
    "\n",
    "                           \n",
    "# Scale the test data\n",
    "test_cols = test_df_final.columns\n",
    "\n",
    "X_test_scaled = scaler.fit_transform(test_df_final)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=test_cols)\n",
    "\n",
    "#X_test_scaled = np.nan_to_num(X_test_scaled)\n",
    "print(X_test_scaled.head())\n",
    "print(X_test_scaled.shape)\n",
    "print(type(X_test_scaled))\n",
    "\n",
    "X_poly_test_all = poly.fit_transform(X_test_scaled)\n",
    "final_res = model_load.predict(X_poly_test_all)\n",
    "\n",
    "final_res_df = pd.DataFrame(final_res , columns = ['salary'])\n",
    "print(final_res_df.head())\n",
    "\n",
    "test_data = pd.concat([test_features_data , final_res_df],axis=1)\n",
    "print(test_data.head())\n",
    "print(test_data.shape)\n",
    "\n",
    "test_data.to_csv('test_features_predicted.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 13 Measure efficacy ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll skip this step since we don't have the outcomes for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
